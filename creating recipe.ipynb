{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582e1a51",
   "metadata": {},
   "source": [
    "# Beginner’s Guide to the GPT-3 Model\n",
    "Demonstrating some interesting example applications in Python, with just a few lines of codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b46970",
   "metadata": {},
   "source": [
    "### Load the openai library\n",
    "\n",
    "To kick off, install and import the openai library. This can be achieved with the Python codes below (in Google Colab or Jupyter notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc26b651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.26.1.tar.gz (55 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->openai) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.6.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->openai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.4)\n",
      "Building wheels for collected packages: openai\n",
      "  Building wheel for openai (PEP 517): started\n",
      "  Building wheel for openai (PEP 517): finished with status 'done'\n",
      "  Created wheel for openai: filename=openai-0.26.1-py3-none-any.whl size=67354 sha256=772fb70dad10440ec8e9fe906ef297343d4d483246dd3e04d39d9b645389c16e\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\5a\\79\\ab\\a8826ab4c3baef7217ae7751e309d649a6fe8e0d6ec4c7b977\n",
      "Successfully built openai\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb39f1",
   "metadata": {},
   "source": [
    "# API Key\n",
    "\n",
    "Before we get into the technical details, an API Key is needed to access GPT-3. This can be obtained by registering an account with OpenAI (for personal use). The API Key can then be viewed under the registered account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3f4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa65056b",
   "metadata": {},
   "source": [
    "# Example Application 1: Create a recipe based on certain ingredients\n",
    "\n",
    "This can be done using the GPT-3 Completion endpoint which can be used for various applications such as Translation, Summarisation, Q & A, and etc. I’ll start by definining a general function which takes texts as input using the Python codes below. This function will be used by all three (3) example applications with different text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c98ac6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPT_Completion(texts):\n",
    "## Call the API key under your account (in a secure way)\n",
    "    openai.api_key = \"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\"\n",
    "    response = openai.Completion.create(\n",
    "    engine=\"text-davinci-002\",\n",
    "    prompt =  texts,\n",
    "    temperature = 0.6,\n",
    "    top_p = 1,\n",
    "    max_tokens = 64,\n",
    "    frequency_penalty = 0,\n",
    "    presence_penalty = 0\n",
    "    )\n",
    "    return print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee67c8d",
   "metadata": {},
   "source": [
    "### You can see that there are a number of parameters under the Completion endpoint, namely:\n",
    "\n",
    "### engine \n",
    "is set to the “text-davinci-002”, which is the “most capable” GPT-3 model based on OpenAI’s documentation.\n",
    "### prompt\n",
    "is set to “text”, which is a variable representing the text input to the function.\n",
    "### temperature \n",
    "sets out how deterministic the output of the model is. A high temperature gives the model more freedom to sample outputs. For example, assuming the probability of returning word A and word B as the next word in a certain task is 80% and 20% respectively. Setting the a ‘low’ temperature (i.e. closer to 0) is likely to return word A on all instances the function is run, whereas setting a ‘high’ temperature (i.e. closer to 1) allows the model to return word B for some instances.\n",
    "top_p sets out the distribution to select the outputs from. Using the same example above, a top_p of 0.75 tells the model to only select word A as it’s the only word with a probability exceeding 0.75.\n",
    "### max_tokens\n",
    "sets out the limit for the number of words to be returned. This may have financial implications as GPT-3 may charge per token for commercial applications. A general rule of thumb is the more words the model is allowed to return, the less ‘abstract’ the outputs will be.\n",
    "\n",
    "frequency_penalty and presence_penalty both are parameters which penalise the model for returning outputs which appear often.\n",
    "Finally, to ask GPT-3 to provide a cooking recipe given ingridents of Apple, Flour, Chicken and Salt, we run the Python codes below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d5d3c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Apple Chicken Recipe\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "1 apple, peeled and diced\n",
      "1/4 cup flour\n",
      "1 chicken breast, cut into small cubes\n",
      "1/4 teaspoon salt\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat oven to 375 degrees Fahrenheit.\n",
      "\n",
      "2. In a small bowl,\n"
     ]
    }
   ],
   "source": [
    "recipe = 'Provide a cooking recipe based on the following ingredients: \\\n",
    "\\n \\nApple \\\n",
    "\\n \\nFlour \\\n",
    "\\n \\nChicken \\\n",
    "\\n \\nSalt'\n",
    "GPT_Completion(recipe)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c97a278",
   "metadata": {},
   "source": [
    "I haven’t tested this recipe out myself but it looks reasonably detailed, noting that relaxing the max_tokens parameter returns even more detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db6dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
